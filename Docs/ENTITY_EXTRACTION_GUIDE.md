# LLM μ—”ν‹°ν‹° μ¶”μ¶ κΈ°λ¥ - μ‚¬μ© κ°€μ΄λ“

## κ°μ”
μ›Ήμ—μ„ μ…λ ¥λ°›μ€ μμ—°μ–΄ ν”„λ΅¬ν”„νΈμ—μ„ **μ¥μ†(location)**μ™€ **λ¬Όν’(item)** μ •λ³΄λ¥Ό μ¶”μ¶ν•λ” κΈ°λ¥μ…λ‹λ‹¤.
- λ΅μ»¬ LLM λ¨λΈ (Ollama): `qwen3:4b-instruct-2507-q4_K_M`
- gRPC ν†µμ‹ μ„ ν†µν• Main μ„λ²„μ™€ AI μ„λ²„ κ°„ μ—°λ™
- λ…λ¦½ ν…μ¤νΈ κ°€λ¥

## κΈ°λ¥
μ‚¬μ©μ μ…λ ¥μ—μ„ λ‹¤μμ„ μ¶”μ¶ν•©λ‹λ‹¤:
- **μ¥μ† (location)**: νμμ‹¤, λ΅λΉ„, 301νΈ, Aλ™ 2μΈµ λ“±
- **λ¬Όν’ (item)**: μ»¤ν”Ό, μ„λ¥, λ…ΈνΈλ¶, λ°•μ¤ λ“±
- **μλ„ (intent)**: μ¶”μ¶λ μ •λ³΄μ— λ”°λΌ μλ™ λ¶„λ¥
  - `deliver_item_to_location`: μ¥μ† + λ¬Όν’
  - `navigate_to_location`: μ¥μ†λ§
  - `find_item`: λ¬Όν’λ§
  - `unknown`: μ—”ν‹°ν‹° μ—†μ

## μ•„ν‚¤ν…μ²
```
μ›Ή μ…λ ¥ β†’ Main Server β†’ gRPC β†’ LLM Server (AI Server) β†’ Ollama LLM
                                    β†“
                              μ—”ν‹°ν‹° μ¶”μ¶ (μ¥μ†/λ¬Όν’)
                                    β†“
                            Main Serverλ΅ κ²°κ³Ό λ°ν™
```

## μ„¤μΉ λ° μ„¤μ •

### 1. ν•„μ ν¨ν‚¤μ§€ μ„¤μΉ
```bash
# Python κ°€μƒν™κ²½ ν™μ„±ν™”
source .venv/bin/activate

# ollama ν¨ν‚¤μ§€ μ„¤μΉ (μ΄λ―Έ μ„¤μΉλ¨)
pip install ollama
```

### 2. Ollama λ¨λΈ ν™•μΈ
```bash
# λ¨λΈμ΄ μ„¤μΉλμ–΄ μλ”μ§€ ν™•μΈ
ollama list

# qwen3:4b-instruct-2507-q4_K_M λ¨λΈμ΄ μμ–΄μ•Ό ν•¨
# μ—†λ‹¤λ©΄ μ„¤μΉ:
# ollama pull qwen3:4b-instruct-2507-q4_K_M
```

### 3. ν™κ²½ λ³€μ μ„¤μ •
`.env` νμΌμ—μ„ LLM λ¨λΈ μ΄λ¦„ ν™•μΈ:
```env
LLM_MODEL_NAME=qwen3:4b-instruct-2507-q4_K_M
LLM_GRPC_PORT=50051
```

## μ‚¬μ© λ°©λ²•

### λ°©λ²• 1: κ°„λ‹¨ν• μ§μ ‘ ν…μ¤νΈ (μ¶”μ²)
LLM μ„λΉ„μ¤λ§ λ‹¨λ…μΌλ΅ ν…μ¤νΈ:

```bash
# Python ν™κ²½μ—μ„ μ‹¤ν–‰
python tests/test_entity_extraction_simple.py
```

**μ¥μ **: gRPC μ„λ²„ μ—†μ΄ λΉ λ¥΄κ² ν…μ¤νΈ κ°€λ¥

**μ¶λ ¥ μμ‹**:
```
[ν…μ¤νΈ 1]
μ…λ ¥: νμμ‹¤λ΅ μ»¤ν”Ό κ°€μ Έλ‹¤μ¤
----------------------------------------
π“ μ¥μ†: νμμ‹¤
π“¦ λ¬Όν’: μ»¤ν”Ό
β“ μ‹ λΆ°λ„: 0.90
```

### λ°©λ²• 2: gRPC μ„λ²„λ¥Ό ν†µν• μ „μ²΄ ν”λ΅μ° ν…μ¤νΈ
μ‹¤μ  ν†µμ‹  ν™κ²½κ³Ό λ™μΌν•κ² ν…μ¤νΈ:

```bash
# 1. LLM μ„λ²„ μ‹μ‘ (λ³„λ„ ν„°λ―Έλ„)
python -m ai_server.llm_server

# 2. gRPC ν…μ¤νΈ μ‹¤ν–‰ (λ‹¤λ¥Έ ν„°λ―Έλ„)
python tests/test_entity_extraction_grpc.py
```

**μ¥μ **: Main μ„λ²„μ™€ λ™μΌν• ν†µμ‹  λ°©μ‹ ν…μ¤νΈ

**μ¶λ ¥ μμ‹**:
```
[ν…μ¤νΈ 1]
μ…λ ¥: νμμ‹¤λ΅ μ»¤ν”Ό κ°€μ Έλ‹¤μ¤
----------------------------------------
π― Intent: deliver_item_to_location
β“ Confidence: 0.90
π“‹ Entities:
  π“ location: νμμ‹¤ (conf: 0.90)
  π“¦ item: μ»¤ν”Ό (conf: 0.90)
```

## ν…μ¤νΈ μΌ€μ΄μ¤ κ²°κ³Ό

| μ…λ ¥ | μ¥μ† | λ¬Όν’ | Intent |
|------|------|------|--------|
| νμμ‹¤λ΅ μ»¤ν”Ό κ°€μ Έλ‹¤μ¤ | νμμ‹¤ | μ»¤ν”Ό | deliver_item_to_location |
| 301νΈμ— μ„λ¥ μ „λ‹¬ν•΄μ¤ | 301νΈ | μ„λ¥ | deliver_item_to_location |
| λ΅λΉ„λ΅ μ΄λ™ν•΄μ¤ | λ΅λΉ„ | - | navigate_to_location |
| λ…ΈνΈλ¶ μ°Ύμ•„μ¤ | - | λ…ΈνΈλ¶ | find_item |
| 3μΈµ νμμ‹¤μ— λ¬Ό ν•μ” κ°€μ Έλ‹¤μ¤ | 3μΈµ νμμ‹¤ | λ¬Ό | deliver_item_to_location |
| μ•λ…•ν•μ„Έμ” | - | - | unknown |
| Aλ™ 2μΈµμΌλ΅ κ°€μ„ λ°•μ¤λ¥Ό κ°€μ Έμ™€μ¤ | Aλ™ 2μΈµ | λ°•μ¤ | deliver_item_to_location |

## API μ‚¬μ©λ²• (Main μ„λ²„ μ—°λ™)

### gRPC ν΄λΌμ΄μ–ΈνΈ μμ‹
```python
import grpc
from ai_server.grpc_impl import ai_services_pb2
from ai_server.grpc_impl import ai_services_pb2_grpc

# gRPC μ±„λ„ μƒμ„±
channel = grpc.insecure_channel('localhost:50051')
stub = ai_services_pb2_grpc.LLMServiceStub(channel)

# μ—”ν‹°ν‹° μ¶”μ¶ μ”μ²­
request = ai_services_pb2.TextRequest(
    text="νμμ‹¤λ΅ μ»¤ν”Ό κ°€μ Έλ‹¤μ¤",
    max_length=200
)

# AnalyzeIntent RPC νΈμ¶
response = stub.AnalyzeIntent(request)

# κ²°κ³Ό ν™•μΈ
print(f"Intent: {response.intent}")
for entity in response.entities:
    print(f"  {entity.type}: {entity.value} (conf: {entity.confidence})")
```

### μ‘λ‹µ κµ¬μ΅°
```protobuf
message IntentResponse {
  string intent = 1;              // deliver_item_to_location, navigate_to_location, find_item, unknown
  float confidence = 2;            // 0.0 ~ 1.0
  repeated Entity entities = 3;    // μ¶”μ¶λ μ—”ν‹°ν‹° λ©λ΅
}

message Entity {
  string type = 1;      // "location" λλ” "item"
  string value = 2;     // "νμμ‹¤", "μ»¤ν”Ό" λ“±
  float confidence = 3; // 0.0 ~ 1.0
}
```

## κµ¬ν„ μ„Έλ¶€μ‚¬ν•­

### LLM ν”„λ΅¬ν”„νΈ μ—”μ§€λ‹μ–΄λ§
```python
system_prompt = """λ‹Ήμ‹ μ€ μ‚¬λ¬΄μ‹¤ λ΅λ΄‡μ„ μ„ν• λ…λ Ήμ–΄ νμ„μ…λ‹λ‹¤.
μ‚¬μ©μμ μ”μ²­μ—μ„ λ‹¤μ μ •λ³΄λ§ μ¶”μ¶ν•μ„Έμ”:
1. location (μ¥μ†): μ) νμμ‹¤, λ΅λΉ„, μ‚¬λ¬΄μ‹¤, 301νΈ, Aλ™ λ“±
2. item (λ¬Όν’): μ) μ»¤ν”Ό, μ„λ¥, λ…ΈνΈλ¶, μƒμ λ“±

λ°λ“μ‹ λ‹¤μ JSON ν•μ‹μΌλ΅λ§ λ‹µλ³€ν•μ„Έμ”:
{"location": "μ¥μ†μ΄λ¦„ λλ” null", "item": "λ¬Όν’μ΄λ¦„ λλ” null"}
"""
```

- **Temperature**: 0.1 (μΌκ΄€λ μ‘λ‹µ)
- **μ¶λ ¥ ν•μ‹**: JSON (κµ¬μ΅°ν™”λ νμ‹±)
- **Fallback**: JSON νμ‹± μ‹¤ν¨ μ‹ μ¤λ¥ μ²λ¦¬

### νμΌ κµ¬μ΅°
```
ai_server/
β”β”€β”€ services/
β”‚   β””β”€β”€ llm_service.py           # Ollama μ—°λ™ λ° μ—”ν‹°ν‹° μ¶”μ¶ λ΅μ§
β”β”€β”€ grpc_impl/
β”‚   β”β”€β”€ llm_servicer.py          # gRPC Servicer (AnalyzeIntent RPC)
β”‚   β”β”€β”€ ai_services.proto         # gRPC μ„λΉ„μ¤ μ •μ
β”‚   β”β”€β”€ ai_services_pb2.py       # μƒμ„±λ protobuf λ©”μ‹μ§€
β”‚   β””β”€β”€ ai_services_pb2_grpc.py  # μƒμ„±λ gRPC stub
β”β”€β”€ docs/                         # λ¬Έμ„ νμΌλ“¤
β”β”€β”€ scripts/                      # μ„λ²„ μ‹μ‘ μ¤ν¬λ¦½νΈλ“¤
β”β”€β”€ llm_server.py                 # LLM gRPC μ„λ²„ μ‹¤ν–‰ (ν¬νΈ 50051)
β””β”€β”€ config.py                     # μ„¤μ • νμΌ

tests/
β”β”€β”€ test_entity_extraction_simple.py   # κ°„λ‹¨ν• ν…μ¤νΈ μ¤ν¬λ¦½νΈ
β”β”€β”€ test_entity_extraction_grpc.py     # gRPC ν…μ¤νΈ μ¤ν¬λ¦½νΈ
β””β”€β”€ ai_server/                          # AI μ„λ²„ κ΄€λ ¨ ν…μ¤νΈλ“¤
```

## νΈλ¬λΈ”μν…

### 1. Ollama μ—°κ²° μ‹¤ν¨
```bash
# Ollama μ„λΉ„μ¤ ν™•μΈ
systemctl status ollama

# λλ” μλ™ μ‹¤ν–‰
ollama serve
```

### 2. λ¨λΈ λ΅λ”© μ‹¤ν¨
```bash
# λ¨λΈ λ‹¤μ‹ λ‹¤μ΄λ΅λ“
ollama pull qwen3:4b-instruct-2507-q4_K_M
```

### 3. gRPC μ—°κ²° μ‹¤ν¨
```bash
# LLM μ„λ²„κ°€ μ‹¤ν–‰ μ¤‘μΈμ§€ ν™•μΈ
ps aux | grep llm_server

# ν¬νΈ ν™•μΈ
netstat -tuln | grep 50051
```

### 4. JSON νμ‹± μ¤λ¥
- LLM μ‘λ‹µμ΄ μμƒν• JSON ν•μ‹μ΄ μ•„λ‹ κ²½μ° λ°μƒ
- `raw_text` ν•„λ“μ—μ„ μ‹¤μ  μ‘λ‹µ ν™•μΈ κ°€λ¥
- Temperatureλ¥Ό λ” λ‚®μ¶”κ±°λ‚ ν”„λ΅¬ν”„νΈ μμ • ν•„μ”

## ν–¥ν›„ ν™•μ¥

### Main μ„λ²„ μ—°λ™
1. Main μ„λ²„μ μ›Ή μΈν„°νμ΄μ¤μ—μ„ μ‚¬μ©μ μ…λ ¥ λ°›κΈ°
2. gRPC ν΄λΌμ΄μ–ΈνΈλ΅ LLM μ„λ²„μ— μ”μ²­
3. μ¶”μ¶λ μ—”ν‹°ν‹°λ΅ Task μƒμ„±
4. Fleet Managerλ¥Ό ν†µν•΄ λ΅λ΄‡ μ μ–΄

### μ¶”κ°€ μ—”ν‹°ν‹° νƒ€μ…
- μ‚¬λ μ΄λ¦„ (person)
- μ‹κ°„ μ •λ³΄ (time)
- μλ‰ (quantity)
- μ°μ„ μμ„ (priority)

### λ€ν™” νμ¤ν† λ¦¬ μ§€μ›
- μ΄μ „ λ€ν™” λ§¥λ½ μ μ§€
- λ€λ…μ‚¬ ν•΄μ„ ("κ±°κΈ°", "κ·Έκ±°")

## μ°Έκ³  μλ£
- Ollama λ¬Έμ„: https://ollama.ai/
- gRPC Python: https://grpc.io/docs/languages/python/
- Qwen λ¨λΈ: https://huggingface.co/Qwen

## λ¬Έμ
μ—”ν‹°ν‹° μ¶”μ¶ μ •ν™•λ„λ¥Ό λ†’μ΄λ ¤λ©΄:
1. ν”„λ΅¬ν”„νΈ μ—”μ§€λ‹μ–΄λ§ μ΅°μ • (system_prompt)
2. Temperature κ°’ μ΅°μ •
3. λ” ν° λ¨λΈ μ‚¬μ© (Qwen3-14B λ“±)
4. Fine-tuning κ³ λ ¤
