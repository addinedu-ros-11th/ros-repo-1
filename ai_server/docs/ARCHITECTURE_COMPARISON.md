# AI Server ì•„í‚¤í…ì²˜ ë¹„êµ

## ğŸ”€ ë‘ ê°€ì§€ ì˜µì…˜

### ì˜µì…˜ 1: í†µí•© ì•„í‚¤í…ì²˜ (Monolithic)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Main Server  â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ gRPC (Port 50051)
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   AI Server             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ LLM Service     â”‚    â”‚
â”‚  â”‚ (Qwen3-4B)      â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ Vision Service  â”‚    â”‚
â”‚  â”‚ (YOLOv8n)       â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ì‹¤í–‰:**
```bash
./ai_server/start_ai_server.sh  # í•˜ë‚˜ì˜ ì„œë²„
```

**Main Server ì½”ë“œ:**
```python
from main_server.core_layer.ai_inference.grpc_inference_client import AIInferenceService

ai = AIInferenceService()  # Port 50051
await ai.request_object_detection("img")
await ai.request_face_recognition("img")
```

**ì¥ì :**
- âœ… ë‹¨ìˆœí•œ êµ¬ì¡° ì´í•´í•˜ê¸° ì‰¬ì›€
- âœ… ë°°í¬ì™€ ê´€ë¦¬ê°€ ê°„ë‹¨
- âœ… í•˜ë‚˜ì˜ ì—°ê²°ë§Œ ê´€ë¦¬
- âœ… ë¦¬ì†ŒìŠ¤ ì˜¤ë²„í—¤ë“œ ìµœì†Œí™”
- âœ… ì¤‘ì†Œê·œëª¨ í”„ë¡œì íŠ¸ì— ì í•©

**ë‹¨ì :**
- âŒ LLM/Vision ë¶€í•˜ê°€ ë‹¬ë¼ë„ í•¨ê»˜ ìŠ¤ì¼€ì¼ë§
- âŒ í•œìª½ ì¥ì• ê°€ ì „ì²´ ì˜í–¥
- âŒ ì„œë¡œ ë‹¤ë¥¸ í•˜ë“œì›¨ì–´ ìš”êµ¬ì‚¬í•­ ì¶©ì¡± ì–´ë ¤ì›€
- âŒ ë…ë¦½ì  ì—…ë°ì´íŠ¸ ë¶ˆê°€

---

### ì˜µì…˜ 2: ë¶„ë¦¬ ì•„í‚¤í…ì²˜ (Microservices) âœ…

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚Main Server  â”‚
â””â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”˜
   â”‚        â”‚
   â”‚        â”‚ gRPC (Port 50052)
   â”‚        â–¼
   â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
   â”‚  â”‚ Vision Server      â”‚
   â”‚  â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
   â”‚  â”‚ â”‚ Vision Service â”‚ â”‚
   â”‚  â”‚ â”‚ (YOLOv8n)      â”‚ â”‚
   â”‚  â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
   â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
   â”‚
   â”‚ gRPC (Port 50051)
   â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ LLM Server         â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ LLM Service    â”‚ â”‚
â”‚ â”‚ (Qwen3-4B)     â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**ì‹¤í–‰:**
```bash
./ai_server/start_all_servers.sh  # ë‘ ê°œì˜ ë…ë¦½ ì„œë²„

# ë˜ëŠ” ê°œë³„ ì‹¤í–‰
./ai_server/start_llm_server.sh    # Port 50051
./ai_server/start_vision_server.sh # Port 50052
```

**Main Server ì½”ë“œ:**
```python
from main_server.core_layer.ai_inference.llm_client import LLMClient
from main_server.core_layer.ai_inference.vision_client import VisionClient

llm = LLMClient()      # Port 50051
vision = VisionClient() # Port 50052

await llm.generate_text("Hello")
await vision.detect_objects("img")
```

**ì¥ì :**
- âœ… ë…ë¦½ì  ìŠ¤ì¼€ì¼ë§ (Vision 3ê°œ, LLM 1ê°œ)
- âœ… ì¥ì•  ê²©ë¦¬ (Vision ë‹¤ìš´â†”LLM ì •ìƒ)
- âœ… í•˜ë“œì›¨ì–´ ìµœì í™” (LLM:CPUì„œë²„, Vision:GPUì„œë²„)
- âœ… ë…ë¦½ ë°°í¬ ë° ì—…ë°ì´íŠ¸
- âœ… ëŒ€ê·œëª¨ í”„ë¡œì íŠ¸ì— ì í•©

**ë‹¨ì :**
- âŒ êµ¬ì¡° ë³µì¡ë„ ì¦ê°€
- âŒ 2ê°œ ì„œë²„ ê´€ë¦¬ í•„ìš”
- âŒ ì¶”ê°€ ë„¤íŠ¸ì›Œí¬ ì—°ê²°

---

## ğŸ“Š ìƒì„¸ ë¹„êµí‘œ

| í•­ëª© | í†µí•© (Monolithic) | ë¶„ë¦¬ (Microservices) |
|------|-------------------|---------------------|
| **ì„œë²„ ìˆ˜** | 1ê°œ | 2ê°œ |
| **í¬íŠ¸** | 50051 | 50051, 50052 |
| **ë°°í¬** | â­â­â­ ë§¤ìš° ì‰¬ì›€ | â­â­ ë³´í†µ |
| **ìŠ¤ì¼€ì¼ë§** | â­ ì œí•œì  (ì „ì²´ë§Œ) | â­â­â­ ìœ ì—° (ê°œë³„) |
| **ì¥ì•  ê²©ë¦¬** | âŒ ì—†ìŒ | âœ… ì™„ì „ |
| **ë¦¬ì†ŒìŠ¤ ìµœì í™”** | â­â­ ì œí•œì  | â­â­â­ ìµœì  |
| **ë…ë¦½ ë°°í¬** | âŒ ë¶ˆê°€ | âœ… ê°€ëŠ¥ |
| **ì—°ê²° ê´€ë¦¬** | â­â­â­ ë‹¨ìˆœ (1ê°œ) | â­â­ ë³´í†µ (2ê°œ) |
| **ê°œë°œ ì†ë„** | â­â­â­ ë¹ ë¦„ | â­â­ ë³´í†µ |
| **ìš´ì˜ ë³µì¡ë„** | â­ ë‚®ìŒ | â­â­â­ ë†’ìŒ |
| **ëª¨ë‹ˆí„°ë§** | â­â­â­ ì‰¬ì›€ | â­â­ ë³´í†µ |
| **ë¡œë“œë°¸ëŸ°ì‹±** | â­ ì œí•œì  | â­â­â­ ìœ ì—° |

---

## ğŸ¯ ì„ íƒ ê°€ì´ë“œ

### í†µí•© ì•„í‚¤í…ì²˜ë¥¼ ì„ íƒí•˜ì„¸ìš” (ì˜µì…˜ 1)

âœ… **ë‹¤ìŒ ì¡°ê±´ì— í•´ë‹¹í•˜ë©´:**
- í”„ë¡œí† íƒ€ì… ë˜ëŠ” PoC ë‹¨ê³„
- ì¤‘ì†Œê·œëª¨ í”„ë¡œì íŠ¸ (ì‚¬ìš©ì < 1000ëª…)
- LLMê³¼ Vision ì‚¬ìš© ë¹ˆë„ê°€ ë¹„ìŠ·í•¨
- ë¹ ë¥¸ ê°œë°œì´ ìš°ì„ ìˆœìœ„
- ë‹¨ìˆœí•œ ì¸í”„ë¼ ì„ í˜¸
- 1-2ëª…ì˜ ì†Œê·œëª¨ íŒ€

ğŸ“‚ **ì‚¬ìš© íŒŒì¼:**
- `ai_server/server.py`
- `ai_server/start_ai_server.sh`
- `main_server/core_layer/ai_inference/grpc_inference_client.py`

---

### ë¶„ë¦¬ ì•„í‚¤í…ì²˜ë¥¼ ì„ íƒí•˜ì„¸ìš” (ì˜µì…˜ 2) âœ…

âœ… **ë‹¤ìŒ ì¡°ê±´ì— í•´ë‹¹í•˜ë©´:**
- í”„ë¡œë•ì…˜ í™˜ê²½
- ëŒ€ê·œëª¨ í”„ë¡œì íŠ¸ (ì‚¬ìš©ì > 1000ëª…)
- LLMê³¼ Vision ì‚¬ìš© íŒ¨í„´ì´ ë‹¤ë¦„
  - ì˜ˆ: Visionì€ 24ì‹œê°„ ì¹´ë©”ë¼, LLMì€ ê°€ë”
- ë…ë¦½ì  ìŠ¤ì¼€ì¼ë§ í•„ìš”
- í•˜ë“œì›¨ì–´ ìµœì í™” í•„ìš”
  - ì˜ˆ: LLMì€ CPU ì„œë²„, Visionì€ GPU ì„œë²„
- ë†’ì€ ê°€ìš©ì„± ìš”êµ¬
- ì„œë¹„ìŠ¤ë³„ ë…ë¦½ ë°°í¬ í•„ìš”

ğŸ“‚ **ì‚¬ìš© íŒŒì¼:**
- `ai_server/llm_server.py`
- `ai_server/vision_server.py`
- `ai_server/start_all_servers.sh`
- `main_server/core_layer/ai_inference/llm_client.py`
- `main_server/core_layer/ai_inference/vision_client.py`

---

## ğŸ”„ ì „í™˜ ë°©ë²•

### í†µí•© â†’ ë¶„ë¦¬ë¡œ ì „í™˜

1. **í™˜ê²½ ë³€ìˆ˜ ì—…ë°ì´íŠ¸**
   ```bash
   # .env íŒŒì¼
   LLM_GRPC_PORT=50051
   VISION_GRPC_PORT=50052
   ```

2. **ì„œë²„ ì‹¤í–‰ ë³€ê²½**
   ```bash
   # Before
   ./ai_server/start_ai_server.sh
   
   # After
   ./ai_server/start_all_servers.sh
   ```

3. **Main Server ì½”ë“œ ìˆ˜ì •**
   ```python
   # Before
   from main_server.core_layer.ai_inference.grpc_inference_client import AIInferenceService
   ai = AIInferenceService()
   
   # After
   from main_server.core_layer.ai_inference.llm_client import LLMClient
   from main_server.core_layer.ai_inference.vision_client import VisionClient
   llm = LLMClient()
   vision = VisionClient()
   ```

### ë¶„ë¦¬ â†’ í†µí•©ìœ¼ë¡œ ì „í™˜

1. **ì„œë²„ ì‹¤í–‰ ë³€ê²½**
   ```bash
   # Before
   ./ai_server/start_all_servers.sh
   
   # After
   ./ai_server/start_ai_server.sh
   ```

2. **Main Server ì½”ë“œ ìˆ˜ì •**
   ```python
   # Before
   from main_server.core_layer.ai_inference.llm_client import LLMClient
   from main_server.core_layer.ai_inference.vision_client import VisionClient
   
   # After
   from main_server.core_layer.ai_inference.grpc_inference_client import AIInferenceService
   ai = AIInferenceService()
   ```

---

## ğŸ’¡ ì¶”ì²œ ì‚¬í•­

### ğŸš€ ì´ˆê¸° ë‹¨ê³„ (ê°œë°œ/í…ŒìŠ¤íŠ¸)
**í†µí•© ì•„í‚¤í…ì²˜ ì‚¬ìš©**
- ë¹ ë¥´ê²Œ í”„ë¡œí† íƒ€ì… ê°œë°œ
- ê¸°ëŠ¥ ê²€ì¦ì— ì§‘ì¤‘
- ë‹¨ìˆœí•œ ì¸í”„ë¼ë¡œ ì‹œì‘

### ğŸ“ˆ ì„±ì¥ ë‹¨ê³„ (ë² íƒ€/ìƒìš©)
**ë¶„ë¦¬ ì•„í‚¤í…ì²˜ë¡œ ì „í™˜**
- ì‚¬ìš©ì ì¦ê°€ì— ëŒ€ì‘
- ë…ë¦½ì  ìŠ¤ì¼€ì¼ë§
- ì•ˆì •ì„± í–¥ìƒ

### ğŸ¯ ìš°ë¦¬ í”„ë¡œì íŠ¸ ì¶”ì²œ

**í˜„ì¬ ìƒí™© ê³ ë ¤:**
- ROS ê¸°ë°˜ ì˜¤í”¼ìŠ¤ ë¡œë´‡ ì„œë¹„ìŠ¤
- ì‹¤ì‹œê°„ ë¹„ì „ ì²˜ë¦¬ í•„ìš” (ì¹´ë©”ë¼)
- ê°€ë” LLM (ìŒì„± ëª…ë ¹, ëŒ€í™”)

**â†’ ë¶„ë¦¬ ì•„í‚¤í…ì²˜ ê¶Œì¥ âœ…**

**ì´ìœ :**
1. Vision(ì¹´ë©”ë¼)ì€ ì§€ì†ì  ë¶€í•˜ â†’ GPU ì„œë²„ 3ëŒ€
2. LLM(ëŒ€í™”)ì€ ê°„í—ì  ë¶€í•˜ â†’ CPU ì„œë²„ 1ëŒ€
3. ë¡œë´‡ì´ ì¦ê°€í•´ë„ Visionë§Œ ìŠ¤ì¼€ì¼ë§
4. í•œìª½ ì„œë¹„ìŠ¤ ì¥ì•  ì‹œì—ë„ ë¡œë´‡ ê¸°ë³¸ ë™ì‘ ìœ ì§€

---

## ğŸ“š ì°¸ê³  ë¬¸ì„œ

- í†µí•© ë°©ì‹: [README.md](README.md)
- ë¶„ë¦¬ ë°©ì‹: [README_SEPARATED.md](README_SEPARATED.md)
- í†µí•© ê°€ì´ë“œ: [INTEGRATION_GUIDE.md](INTEGRATION_GUIDE.md)
